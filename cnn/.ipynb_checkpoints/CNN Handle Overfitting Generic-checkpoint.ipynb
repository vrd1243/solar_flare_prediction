{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(torch.nn.Module):\n",
    "        \n",
    "    #Our batch shape for input x is (4, 256, 256)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        #Input channels = 4, output channels = 8\n",
    "        self.conv1 = torch.nn.Conv2d(4, 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        #Input channels = 8, output channels = 16\n",
    "        self.conv2 = torch.nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        #Input channels = 16, output channels = 32\n",
    "        self.conv3 = torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        #Input channels = 32, output channels = 64\n",
    "        self.conv4 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool4 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        #4608 input features, 64 output features (see sizing flow below)\n",
    "        self.fc1 = torch.nn.Linear(32 * 32 * 32, 64)\n",
    "        \n",
    "        #64 input features, 10 output features for our 2 defined classes\n",
    "        self.fc2 = torch.nn.Linear(64, 2)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(0.01)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Computes the activation of the first convolution\n",
    "        #Size changes from (4, 256, 256) to (8, 256, 256)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        #Size changes from (8, 256, 256) to (8, 128, 128)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        #Size changes from (8, 128, 128) to (16, 128, 128)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        #Size changes from (16, 128, 128) to (16, 64, 64)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        #Size changes from (16, 64, 64) to (32, 64, 64)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        \n",
    "        #Size changes from (32, 64, 64) to (32, 32, 32)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        #Size changes from (32, 32, 32) to (64, 32, 32)\n",
    "        #x = F.relu(self.conv4(x))\n",
    "        \n",
    "        #Size changes from (64, 32, 32) to (64, 16, 16)\n",
    "        #x = self.pool4(x)\n",
    "        \n",
    "        #Reshape data to input to the input layer of the neural net\n",
    "        #Size changes from (32, 32, 32) to (1, 4608)\n",
    "        #Recall that the -1 infers this dimension from the other given dimension\n",
    "        x = x.view(-1, 32 * 32 * 32)\n",
    "        \n",
    "        #Computes the activation of the first fully connected layer\n",
    "        #Size changes from (1, 32768) to (1, 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        #x = self.dropout(x)\n",
    "        \n",
    "        #Computes the second fully connected layer (activation applied later)\n",
    "        #Size changes from (1, 64) to (1, 2)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        #return(F.log_softmax(x, dim=1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device()\n",
    "torch.cuda.device(0)\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sunspotDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,text_file,root_dir,transform):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text_file(string): path to text file\n",
    "            root_dir(string): directory with all train images\n",
    "        \"\"\"\n",
    "        self.name_frame = pd.read_csv(text_file,sep=\",\",usecols=range(1), header='infer')\n",
    "        self.label_frame = pd.read_csv(text_file,sep=\",\",usecols=range(1,2), header='infer')\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.name_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.name_frame.iloc[idx, 0])\n",
    "        image = Image.open(img_name)\n",
    "        image = image.resize((256, 256))#, Image.AFFINE)\n",
    "        image = self.transform(image)\n",
    "    \n",
    "        labels = self.label_frame.iloc[idx, 0]\n",
    "        #labels = labels.reshape(-1, 2)\n",
    "        #sample = {'image': image, 'labels': labels}\n",
    "\n",
    "        return [image, labels]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sunspotTrainSet = sunspotDataset(df_train, root_dir = '../../data/all_images/', transform=transform)\n",
    "#sunspotValidSet = sunspotDataset(df_valid, root_dir = '../../data/all_images/', transform=transform)\n",
    "import importlib\n",
    "import data\n",
    "importlib.reload(data)\n",
    "\n",
    "df = pd.read_csv(\"/srv/data/varad/data/all_labels.csv\", sep=\",\", header='infer')\n",
    "sunspotTrainSet, sunspotValidSet = data.generateTrainValidData(df, root_dir='/', splitType='random')\n",
    "\n",
    "def get_loader(set, sampler, batch_size):    \n",
    "    sunspotLoader = torch.utils.data.DataLoader(set, sampler=sampler, num_workers=2, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return sunspotLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def createLossAndOptimizer(net, learning_rate, weight):\n",
    "        \n",
    "    reg_loss = 0\n",
    "    for param in net.parameters():\n",
    "        reg_loss += torch.sum(torch.abs(param))\n",
    "\n",
    "    #Loss function\n",
    "    loss = torch.nn.CrossEntropyLoss(weight=weight)\n",
    "    \n",
    "    #Optimizer\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0.001)\n",
    "    \n",
    "    return(loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def trainNet(net, batch_size, n_epochs, learning_rate):\n",
    "    \n",
    "    #Print all of the hyperparameters of the training iteration:\n",
    "    print(\"===== HYPERPARAMETERS =====\")\n",
    "    print(\"batch_size=\", batch_size)\n",
    "    print(\"epochs=\", n_epochs)\n",
    "    print(\"learning_rate=\", learning_rate)\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    #Get training data\n",
    "    train_loader = get_loader(sunspotTrainSet, sampler=None, batch_size=batch_size)\n",
    "    val_loader = get_loader(sunspotValidSet, sampler=None, batch_size=batch_size)\n",
    "        \n",
    "    n_batches = len(train_loader)\n",
    "    \n",
    "    weight = torch.FloatTensor([1,10]).to(device)\n",
    "    #Create our loss and optimizer functions\n",
    "    loss, optimizer = createLossAndOptimizer(net, learning_rate, weight)\n",
    "    \n",
    "    #Time for printing\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    #Loop for n_epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        print_every = n_batches // 10\n",
    "        start_time = time.time()\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        net.train()\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            #Get inputs\n",
    "            inputs, labels = data\n",
    "            \n",
    "            #Wrap them in a Variable object\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            #Set the parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #Forward pass, backward pass, optimize\n",
    "            outputs = net(inputs)\n",
    "            loss_size = loss(outputs, labels)\n",
    "            loss_size.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Print statistics\n",
    "            running_loss += loss_size.data.item()\n",
    "            total_train_loss += loss_size.data.item()\n",
    "            \n",
    "            #Print every 10th batch of an epoch\n",
    "        \n",
    "            if (i + 1) % (print_every + 1) == 0:\n",
    "                print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(\n",
    "                        epoch+1, int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))\n",
    "                #Reset running loss and time\n",
    "                running_loss = 0.0\n",
    "                start_time = time.time()\n",
    "            \n",
    "        #At the end of the epoch, do a pass on the validation set\n",
    "        total_val_loss = 0\n",
    "        confusion_matrix = torch.zeros(2, 2)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        net.eval()\n",
    "        for inputs, labels in val_loader:\n",
    "            \n",
    "            #Wrap tensors in Variables\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "            #Forward pass\n",
    "            val_outputs = net(inputs)\n",
    "            _, predicted = torch.max(val_outputs.data, 1)        \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "            val_loss_size = loss(val_outputs, labels)\n",
    "            total_val_loss += val_loss_size.data.item()\n",
    "            \n",
    "        tp = confusion_matrix[1,1]\n",
    "        tn = confusion_matrix[0,0]\n",
    "        fp = confusion_matrix[0,1]\n",
    "        fn = confusion_matrix[1,0]\n",
    "\n",
    "        print(\"Validation loss = {:.2f}\".format(total_val_loss / len(val_loader)))\n",
    "        print(\"TSS = {:.2f}\".format((tp) / (tp + fn) - (fp) / (fp + tn)))\n",
    "        print(\"TP = {}, FP = {}, FN = {} TN  = {}\".format(tp, fp, fn, tn))\n",
    "        print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "\n",
    "CNN = SimpleCNN();\n",
    "CNN.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 128\n",
      "epochs= 2\n",
      "learning_rate= 0.001\n",
      "==============================\n",
      "Epoch 1, 10% \t train_loss: 0.68 took: 817.55s\n",
      "Epoch 1, 20% \t train_loss: 0.67 took: 821.71s\n",
      "Epoch 1, 30% \t train_loss: 0.68 took: 828.39s\n",
      "Epoch 1, 40% \t train_loss: 0.67 took: 831.01s\n",
      "Epoch 1, 50% \t train_loss: 0.67 took: 899.01s\n",
      "Epoch 1, 60% \t train_loss: 0.67 took: 939.18s\n",
      "Epoch 1, 70% \t train_loss: 0.67 took: 983.54s\n"
     ]
    }
   ],
   "source": [
    "trainNet(CNN, batch_size=128, n_epochs=2, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 13 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "val_loader = get_loader(sunspotValidSet, sampler=None, batch_size=64)\n",
    "confusion_matrix = torch.zeros(2, 2)\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        #Get inputs\n",
    "        inputs, labels = data\n",
    "            \n",
    "        #Wrap them in a Variable object\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = CNN(inputs)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
    "            confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     0., 129325.],\n",
      "        [     0.,  20668.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "tp = confusion_matrix[1,1]\n",
    "tn = confusion_matrix[0,0]\n",
    "fp = confusion_matrix[0,1]\n",
    "fn = confusion_matrix[1,0]\n",
    "\n",
    "print((tp) / (tp + fn) - (fp) / (fp + tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
